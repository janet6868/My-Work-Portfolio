---
title: "Paddy Flooding Detection with Remote Sensing"
date: today
date-format: long
author: "Financial Instruments"
format:
  html:
  
    page-layout: full
    theme:
          light: flatly
          dark: darkly
    toc: false
    toc-depth: 3
    toc-location: left
    number-sections: false
    smooth-scroll: true
execute:
    echo: false
    warning: false
    enable: true
title-block-banner: true
---

```{=html}
<style type="text/css">

h1.title {
  font-size: 20px;
  color: White;
  text-align: center;
}
h4.author { /* Header 4 - and the author and data headers use this too  */
    font-size: 16px;
  font-family: "Source Sans Pro Semibold", Times, serif;
  color: Red;
  text-align: center;
}
h4.date { /* Header 4 - and the author and data headers use this too  */
  font-size: 16px;
  font-family: "Source Sans Pro Semibold", Times, serif;
  color: Red;
  text-align: center;
}

.justify {
  text-align: justify !important
}

</style>
```


------------------------------------------------------------------------

::: {style="text-align:center"}
<h2>Dagana dry hot season flooding detection analysis</h2>
:::

</br>

### Overview

::: { .callout-note}

::: {.justify}
We demonstrate the flooding activities and the impact of credit access. We can also include various other analyses in the  bulletin to provide a comprehensive overview of the flooding activities. Here are some suggestions:

A brief summary of the analysis:

    - Flooding timelines-analyze the flooding data over time to identify trends and patterns.
        - Create a line chart or area chart to visualize the flooding area or number of affected locations over the given time period.
        - Highlight significant events or peak flooding periods..
    - Flooding Progression: Analyze how the flooding progressed over time in different locations.
        - Create a heatmap or a series of maps to visualize the spatial and temporal distribution of flooding.
        - Identify areas where flooding started early or persisted for a longer duration.
    - Comparison with Historical Data-
        -  Use historical (previous years) flooding data, compare the current season flooding activities.
        - Create a bar chart or line chart to show the comparison and highlight any significant deviations.
        - Provide insights into whether the current flooding is above or below historical levels.
    - Impact Analysis on access to credit.
        - Assess the potential impact of early access to credit on flooding on various locations.
        - Analyze the data in relation to land use, SRI practices, population density, or critical infrastructure.
        - Create a risk map or categorize localities into different risk levels.
        - Provide recommendations for late flooding/ planting mitigation measures or preparedness planning.

*Variable included*

    - crop_name: Rice
    - Region: Dagana, Senegal
    - season_name:  Dry hot season 
    - planting_year: 2024
    - Estimated flooding dates

:::
:::

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap, BoundaryNorm
from matplotlib.dates import DateFormatter, DayLocator
import seaborn as sns
import geopandas as gpd
import rasterio as rio
from rasterio.plot import show
import geemap
import folium
from IPython.display import display, HTML, Markdown
from datetime import datetime
from shapely import wkt
import json
from folium.plugins import MarkerCluster


```

::: { .callout-tip}

#### Flooding activities progress and timeline analysis
::: {.justify}
The cumulative flooding data for each day we have a Copernicus Sentinel 2 image. 
At the end of SAED planting window - March 15th we have 20785.59 ha flooded.
:::
:::

```{python}
#rs_data with duplicate plots---1431
rs_mndwi_data_2024 = pd.read_csv(r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\workflow\Dry_hot_season\2024\servir_2024\servir_flooding_data\dataframe\final_result\flooding_Dagana2024.csv",index_col=0)

# Select columns that match the date format
clean_df = rs_mndwi_data_2024[~np.array(rs_mndwi_data_2024['flooding_date']=='0')]

clean_df ['RS flooding doy'] = pd.to_datetime( clean_df ['flooding_date']).dt.dayofyear
rs_hueristics_df = clean_df.filter(regex=('\d{4}-?\d{2}-?\d{2}$'))

area_rs_24 = rs_hueristics_df.sum(axis=0)
rs_df_24 = pd.DataFrame()
rs_df_24['Date'] = list(area_rs_24.index)
rs_df_24['Area(ha)'] = list(area_rs_24.values)
rs_df_24['Data_source'] ='S2 MNDWI 2024'

html_table = rs_df_24.to_html(index=True)

# Wrap in a scrollable div
scrollable_table = f"""
<div style="height: 400px; width: 100%; overflow-x: auto; overflow-y: auto;">
    {html_table}
</div>
"""
# Display the scrollable table
display(HTML(scrollable_table))

#************** timeline****************

# Convert date strings to datetime objects
start_date = datetime.strptime('2024-02-15', '%Y-%m-%d')
end_date = datetime.strptime('2024-03-15', '%Y-%m-%d')

# Create a line plot
fig, ax = plt.subplots(figsize=(10, 6))

# Add vertical lines for start and end dates
ax.axvline(start_date, color='black', linestyle='--')
ax.axvline(end_date, color='black', linestyle='--')

# Add labels for the vertical lines
ax.text(start_date, 15000, 'Start planting (15FEB)', ha='right', va='bottom', color='black')
ax.text(end_date, 15000, 'End planting (15MARCH)', ha='left', va='bottom', color='black')

# Convert the 'Time' column to datetime
rs_df_24['Date'] = pd.to_datetime(rs_df_24['Date'])
rs_df_24['date'] = pd.to_datetime(rs_df_24['Date'])

# Create a line plot
ax.plot(rs_df_24['Date'], rs_df_24['Area(ha)'], label='RS flooded area', marker='o', linestyle='-')
ax.set_title('2024 DHS remote sensing detected cumulative flooded area- Dagana')
ax.set_xlabel('Date')
ax.set_ylabel('Area (ha)')

# Customize the x-axis time interval
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability

# Create a DayLocator with the desired interval (e.g., 7 days for weekly ticks)
desired_interval = 15
day_locator = DayLocator(interval=desired_interval)

# Format the date labels
date_format = DateFormatter("%Y-%m-%d")

# Set the x-axis locator and formatter
ax.xaxis.set_major_locator(day_locator)
ax.xaxis.set_major_formatter(date_format)

# Add the legend with specified edgecolor
legend = ax.legend(frameon=True, edgecolor='black')
frame = legend.get_frame()
frame.set_facecolor('white')  # Set the legend background color
frame.set_linewidth(1)  # Adjust the border thickness

ax.grid(True)

# Identify peak flooding periods
peak_flooding_dates = rs_df_24.nlargest(3, 'Area(ha)')
rs_df_24['date'] = pd.to_datetime(rs_df_24['Date'])

# Generate the analysis for the bulletin
timeline_analysis = f"""

Key observations:


    - The peak flooding periods occurred on the following dates:

        1. {peak_flooding_dates.iloc[0]['date'].strftime('%Y-%m-%d')}: {peak_flooding_dates.iloc[0]['Area(ha)']:.2f}

        2. {peak_flooding_dates.iloc[1]['date'].strftime('%Y-%m-%d')}: {peak_flooding_dates.iloc[1]['Area(ha)']:.2f}

        3. {peak_flooding_dates.iloc[2]['date'].strftime('%Y-%m-%d')}: {peak_flooding_dates.iloc[2]['Area(ha)']:.2f}

"""

# Display the timeline analysis and the plot
display(Markdown(timeline_analysis))
plt.tight_layout()
plt.show()
```

 ::: { .callout-tip}
#### Mapping the flooding activities
::: {.justify}
The flooding activities data was analyzed over the given time period to identify trends and patterns. 

Key observations:

  1. Flooding maps - that depict the extent of the flooded rice area across the plots in the region, between January and 1st July. 
  2. The spatial distribution of the estimated dates in the region.
:::
:::

```{python}

#++++++++++++++++++++ Plotting the flooding map  +++++++++++++++++++++++++++++
# Read the raster data
map_path = r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\workflow\Dry_hot_season\Maps\flooding_map_Daganaser_2024.tif"
# Read the boundary data
boundary_path = r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\workflow\Dry_hot_season\dagana_region.geojson"
with rio.open(map_path) as src:
    mp = src.read(1)
    extent = rio.plot.plotting_extent(src)
boundary = gpd.read_file(boundary_path)
# Reproject the boundary to match the CRS of the raster data
boundary = boundary.to_crs(src.crs)
# Create a figure and axis
fig, ax = plt.subplots(figsize=(15, 15))
# Plot the raster data with dark blue colormap
show(mp, ax=ax, cmap='Blues', extent=extent)
# Plot the boundary
boundary.plot(ax=ax, facecolor="none", edgecolor="black")
# Create a ScalarMappable for the colorbar
sm = plt.cm.ScalarMappable(cmap='Blues')
sm.set_array(mp)
cbar = plt.colorbar(sm, ax=ax, shrink=0.6)
cbar.set_label('Flooding day of the year')
# Set the title
plt.title('Dagana flooding map to 26th May, 2024 ')
# Display the plot
plt.show()

# Load the GeoTIFF file
with rio.open(map_path) as src:
    # Extract the raster data and the bounding box
    data = src.read(1)
    bounds = src.bounds

# Create a folium map centered at the center of the bounding box
m = folium.Map(location=[(bounds.bottom + bounds.top)/2, (bounds.left + bounds.right)/2],
               zoom_start=10,
               tiles='https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png',
               attr='Map data Â© <a href="https://openstreetmap.org">OpenStreetMap</a> contributors')

# Add the raster layer to the map
folium.raster_layers.ImageOverlay(data,
                             bounds=[(bounds.bottom, bounds.left), (bounds.top, bounds.right)],
                             colormap=lambda x: (0, 0, 1, x),
                             mercator_project=True).add_to(m)

# Display the map
m
```

```{python}
map_path = r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\workflow\Dry_hot_season\Maps\flooding_map_Daganaser_2024.tif"
# Read the boundary data
boundary_path = r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\workflow\Dry_hot_season\dagana_region.geojson"

with rio.open(map_path) as src:
    mp = src.read(1)
    extent = rio.plot.plotting_extent(src)
    nodata_value = src.nodata

# Mask out no data values (if any)
mp_masked = np.ma.masked_equal(mp, nodata_value)
# Create custom colormap with green and red colors
colors = ['white', '#38E54D', '#FF1E1E']
bounds = [0, 7, 77, np.max(mp)]  # Values below 77 are green, above or equal to 77 are red
cmap = ListedColormap(colors)
norm = BoundaryNorm(bounds, len(colors))
# Initialize geemap
Map = geemap.Map(center=[0, 0], zoom=2)
# Add the masked flooding map to geemap
Map.add_raster(map_path, colormap=cmap, layer_name='Flooding Map')
# Read and add the boundary shapefile to geemap
boundary = gpd.read_file(boundary_path)
Map.add_gdf(boundary, layer_name='Boundary')
# Display the map
Map

# Create a figure and axis for static plotting
fig, ax = plt.subplots(figsize=(12, 12))
# Set background color to white
ax.set_facecolor('white')
# Plot the flooding map with custom colormap
show(mp_masked, ax=ax, extent=extent, alpha=0.5, cmap=cmap, norm=norm)
# Plot the boundary
boundary.plot(ax=ax, facecolor="none", edgecolor="black")
# Set plot title and labels
ax.set_title('Risk analysis based on flooding dates', fontsize=14)
ax.set_xlabel('Longitude', fontsize=12)
ax.set_ylabel('Latitude', fontsize=12)
# Add data source and relevant details
data_source = "Data Source: Remote Sensing Analysis"
relevant_details = "Date Range: January 2024 - July 2024"
ax.annotate(data_source + "\n" + relevant_details, xy=(0.5, -0.15), xycoords='axes fraction', ha='center', fontsize=10)

# Create custom legend
handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]
labels = ['No data', 'Plots at low risk - flooded and planted in time', 'Plots at risk - flooded/planted past SAED window']
ax.legend(handles, labels, title='Risk analysis', loc='lower right')

plt.tight_layout()
plt.show()

```


::: { .callout-tip}
#### Risky analysis associated to flooding 
::: {.justify}

We utilize the flooding dates information to classify the plots that have experienced flooding and have been planted within the SAED window, which spans from February 15th to March 15th. Given that the latest image is from March 17th, plots are categorized as low risk if the flooding date falls on or before the 77th day of the year and as high risk if flooded/planted after day 77.
:::
:::

```{python}
#************** spatial distribution********************
map_path = r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\workflow\Dry_hot_season\Maps\flooding_map_Daganaser_2024.tif"
# Read the boundary data
boundary_path = r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\workflow\Dry_hot_season\dagana_region.geojson"
# Read the flooding map
with rio.open(map_path) as src:
    mp = src.read(1)
    extent = rio.plot.plotting_extent(src)

# Mask out no data values (if any)
nodata_value = src.nodata
mp_masked = np.ma.masked_equal(mp, nodata_value)

# Create custom colormap with green and red colors
colors = ['white','#38E54D', '#FF1E1E']
bounds = [0, 7, 77, np.max(mp)]  # Values below 77 are green, above or equal to 77 are red
cmap = ListedColormap(colors)
norm = BoundaryNorm(bounds, len(colors))

# Create a figure and axis
fig, ax = plt.subplots(figsize=(12, 12))

# Set background color to white
ax.set_facecolor('white')

# Plot the flooding map with custom colormap
show(mp_masked, ax=ax, extent=extent, alpha=0.5, cmap=cmap, norm=norm)

# Plot the boundary
boundary.plot(ax=ax, facecolor="none", edgecolor="black")

# Set plot title and labels
ax.set_title('Risk analysis based on flooding dates', fontsize=14)
ax.set_xlabel('Longitude', fontsize=12)
ax.set_ylabel('Latitude', fontsize=12)

# Add data source and relevant details
data_source = "Data Source: Remote Sensing Analysis"
relevant_details = "Date Range: January 2024 -  July 2024"
ax.annotate(data_source + "\n" + relevant_details, xy=(0.5, -0.15), xycoords='axes fraction', ha='center', fontsize=10)

# Create custom legend
handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]
labels = ['No data','Plots at low risk-flooded and planted in time', 'Plots at risk -flooded/planted past SAED window']
ax.legend(handles, labels, title='Risk analysis', loc='lower right')
plt.tight_layout()
plt.show()

display()
```

::: { .callout-tip}
#### Comparison with previous seasons
::: {.justify}
The SAED forecast for 2024 predicts a decrease to 39,850 hectares under rice cultivation compared to 2023, when it was 41,000 hectares. In both the remotely sensed data and SAED records, the flooded (planted for SAED) area was higher in 2023 than in 2024.
:::
:::

```{python}
# Load data
rs_mndwi_data_2023 = pd.read_csv(r'G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\workflow\Dry_hot_season\2024\servir_2023\servir_flooding_data_2023\dataframe\final_result\flooding_Dagana2023.csv', index_col=0)
rs_vv_data_2024 = pd.read_csv(r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\sentinel_one\flooding_data_s1_dagana_vv_2024.csv", index_col=0)
rs_vh_data_2024 = pd.read_csv(r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\sentinel_one\flooding_data_s1_dagana_vh_2024.csv", index_col=0)
rs_vv_data_2023 = pd.read_csv(r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\sentinel_one\flooding_data_s1_dagana_vv_2023.csv", index_col=0)
rs_vh_data_2023 = pd.read_csv(r"G:\My Drive\HEURISTICS\SRV_flooding_detection_models\Dagana\sentinel_one\flooding_data_s1_dagana_vh_2023.csv", index_col=0)
saed_2019_2024_dhs = pd.read_csv(r"G:\\My Drive\\HEURISTICS\\SRV_flooding_detection_models\\Dagana\\workflow\\Dry_hot_season\\2024\\saed_bulletins\\saed_2019_2024.csv")
saed_2019_2024_dhs['date'] = pd.to_datetime(saed_2019_2024_dhs['Date'])

# Process MNDWI data for 2023
rs_hueristics_dff_2023 = rs_mndwi_data_2023.filter(regex=('\\d{4}-?\\d{2}-?\\d{2}$'))
area_rs_23 = rs_hueristics_dff_2023.sum(axis=0)
rs_df_23 = pd.DataFrame()
rs_df_23['Date'] = list(area_rs_23.index)
rs_df_23['Area(ha)'] = list(area_rs_23.values)
rs_df_23['Data_source'] = 'S2 MNDWI 2023'
rs_df_23['date'] = pd.to_datetime(rs_df_23['Date'])

# Process S1 VV and VH data for 2024
area_vv_24 = rs_vv_data_2024.filter(regex=('\\d{4}-?\\d{2}-?\\d{2}$')).sum(axis=0)
rs_df_vv_24 = pd.DataFrame()
rs_df_vv_24['Date'] = list(area_vv_24.index)
rs_df_vv_24['Area(ha)'] = list(area_vv_24.values)
rs_df_vv_24['Data_source'] = 'S1 VV 2024'
rs_df_vv_24['date'] = pd.to_datetime(rs_df_vv_24['Date'])

area_vh_24 = rs_vh_data_2024.filter(regex=('\\d{4}-?\\d{2}-?\\d{2}$')).sum(axis=0)
rs_df_vh_24 = pd.DataFrame()
rs_df_vh_24['Date'] = list(area_vh_24.index)
rs_df_vh_24['Area(ha)'] = list(area_vh_24.values)
rs_df_vh_24['Data_source'] = 'S1 VH 2024'
rs_df_vh_24['date'] = pd.to_datetime(rs_df_vh_24['Date'])

# Process S1 VV and VH data for 2023
area_vv_23 = rs_vv_data_2023.filter(regex=('\\d{4}-?\\d{2}-?\\d{2}$')).sum(axis=0)
rs_df_vv_23 = pd.DataFrame()
rs_df_vv_23['Date'] = list(area_vv_23.index)
rs_df_vv_23['Area(ha)'] = list(area_vv_23.values)
rs_df_vv_23['Data_source'] = 'S1 VV 2023'
rs_df_vv_23['date'] = pd.to_datetime(rs_df_vv_23['Date'])

area_vh_23 = rs_vh_data_2023.filter(regex=('\\d{4}-?\\d{2}-?\\d{2}$')).sum(axis=0)
rs_df_vh_23 = pd.DataFrame()
rs_df_vh_23['Date'] = list(area_vh_23.index)
rs_df_vh_23['Area(ha)'] = list(area_vh_23.values)
rs_df_vh_23['Data_source'] = 'S1 VH 2023'
rs_df_vh_23['date'] = pd.to_datetime(rs_df_vh_23['Date'])

# Filter SAED data for 2023 and 2024
saed_data_2023 = saed_2019_2024_dhs[saed_2019_2024_dhs['date'].dt.year == 2023]
saed_data_2024 = saed_2019_2024_dhs[saed_2019_2024_dhs['date'].dt.year == 2024]

# Combine dataframes for 2023
combined_df_2023 = pd.concat([rs_df_23, rs_df_vv_23, rs_df_vh_23, saed_data_2023])
combined_df_2023['Day'] = combined_df_2023['date'].dt.day
combined_df_2023['Month'] = combined_df_2023['date'].dt.month
combined_df_2023['Year'] = combined_df_2023['date'].dt.year
combined_df_2023['Days'] = combined_df_2023['date'].dt.dayofyear

# Combine dataframes for 2024
combined_df_2024 = pd.concat([rs_df_24, rs_df_vv_24, rs_df_vh_24, saed_data_2024])
combined_df_2024['Day'] = combined_df_2024['date'].dt.day
combined_df_2024['Month'] = combined_df_2024['date'].dt.month
combined_df_2024['Year'] = combined_df_2024['date'].dt.year
combined_df_2024['Days'] = combined_df_2024['date'].dt.dayofyear

# Define a consistent color palette for all data sources
palette = {
    'S2 MNDWI 2023': 'green',
    'S2 MNDWI 2024': 'green',
    'S1 VV 2023': 'blue',
    'S1 VH 2023': 'red',
    'SAED prepared area 2023': 'purple',
    'SAED planted area 2023': 'orange',
    'S2 MNDWI 2024': 'green',
    'S1 VV 2024': 'blue',
    'S1 VH 2024': 'red',
    'SAED prepared area 2024': 'purple',
    'SAED planted area 2024': 'orange'
}

# Plotting
fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)

# Plot for 2023
sns.lineplot(ax=axes[0], data=combined_df_2023, x='Days', y='Area(ha)', hue='Data_source', marker='o', palette=palette)
axes[0].set_title('Flooded area over time with RS and SAED data (2023)')
axes[0].set_xlabel('Day of the year')
axes[0].set_ylabel('Area (ha)')
axes[0].legend(title='Data Source', bbox_to_anchor=(1.05, 1), loc='upper left')
axes[0].grid(True)

# Plot for 2024
sns.lineplot(ax=axes[1], data=combined_df_2024, x='Days', y='Area(ha)', hue='Data_source', marker='o', palette=palette)
axes[1].set_title('Flooded area over time with RS and SAED data (2024)')
axes[1].set_xlabel('Day of the year')
axes[1].set_ylabel('Area (ha)')
axes[1].legend(title='Data Source', bbox_to_anchor=(1.05, 1), loc='upper left')
axes[1].grid(True)

plt.tight_layout()
plt.show()

```

```


